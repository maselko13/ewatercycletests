name: pull-check
run-name: pullCheck
on:
   pull_request:
       types: [ reopened, opened ]
env:
  PASS: tests passed!
jobs:
  Test-request-file:
    # ensures only plugin addition pull requests are checked
    if: startsWith(github.event.pull_request.title, 'add model:') &&  github.event.pull_request.base.ref == 'main' 
    runs-on: self-hosted
    steps:
        - name: checkout submission branch
          uses: actions/checkout@v4
          with: 
             ref: ${{github.head_ref}}
        - name: Get changed files
          id: changed-files
          uses: tj-actions/changed-files@v44
       # - name: check changed files
       #   env:
      #     ALL_CHANGED_FILES: ${{ steps.changed-files.outputs.all_changed_files }}
     #     run: |
    #       [ "${{env.ALL_CHANGED_FILES}}" == "models.txt" ] || exit 1
        - name: create-directory-for-model-repo
          run: mkdir second
        - name: model-list-tests
          run: conda run -n ewatercycle --no-capture-output python ModelsModificationTests.py
          # the submission file test outputs the path to the plugin file repository, which is stored as a a variable in order to clone it in the next step.
        - name: model-list-tests-as-output
          run: echo "REPO=$(conda run -n ewatercycle --no-capture-output python ModelsModificationTests.py)" >> "$GITHUB_ENV" 
        - name: clone-repo
          uses: actions/checkout@v4
          with:
              repository: ${{env.REPO}}
              ref: main
              path: second
  #      - name: move-model-file
 #         run: mv -f second/Mocks.py .
        - name: install-plugin
          run: pip install git+https://github.com/eWaterCycle/leakybucket-bmi
        - name: move-submission-file
          run: mv -f second/submission.yml .
        - name: submission-file-tests
          run: conda run -n ewatercycle --no-capture-output python PluginSubmissionTests.py
  Test-model:
    needs: Test-request-file
    # ensures only plugin addition pull requests are checked
    if: startsWith(github.event.pull_request.title, 'add model:') &&  github.event.pull_request.base.ref == 'main' 
    runs-on: self-hosted
    permissions:
      contents: write
    steps:  
        - name: clone-repo
          uses: actions/checkout@v4
          with:
              ref: main
              repository: ${{steps.submission-file-tests.outputs.repository}}
              path: second
        - name: run-model-tests
          run: conda run -n ewatercycle --no-capture-output python main.py
        - name: run-model-tests-as-output
          run: echo "RESULT=$(conda run -n ewatercycle --no-capture-output python main.py)" >> "$GITHUB_ENV" 
        - name: upload-test-results
          uses: actions/upload-artifact@v4
          with:
               name: test result
               path: output/testReport.yaml
        - name: Get Artifact and Pull request info
          env:
            GITHUB_TOKEN: ${{ github.token }}
            WORKFLOW_RUN_EVENT_OBJ: ${{ toJSON(github.event.workflow_run) }}
            OWNER: ${{ github.repository_owner }}
            REPO: ${{ github.event.repository.name }}
          run: |
            PREVIOUS_JOB_ID=$(jq -r '.id' <<< "$WORKFLOW_RUN_EVENT_OBJ")
            echo "Previous Job ID: $PREVIOUS_JOB_ID"
            echo "PREVIOUS_JOB_ID=$PREVIOUS_JOB_ID" >> "$GITHUB_ENV"
          
            SUITE_ID=$(jq -r '.check_suite_id' <<< "$WORKFLOW_RUN_EVENT_OBJ")
            echo "Previous Suite ID: $SUITE_ID"
            echo "SUITE_ID=$SUITE_ID" >> "$GITHUB_ENV"
          
            ARTIFACT_ID=$(gh api "/repos/$OWNER/$REPO/actions/artifacts" \
              --jq ".artifacts.[] |
              select(.workflow_run.id==${PREVIOUS_JOB_ID}) |
              select(.expired==false) |
              .id")
          
            echo "Artifact ID: $ARTIFACT_ID"
            echo "ARTIFACT_ID=$ARTIFACT_ID" >> "$GITHUB_ENV"
          
            PR_NUMBER=$(jq -r '.pull_requests[0].number' \
              <<< "$WORKFLOW_RUN_EVENT_OBJ")
          
            echo "Pull request Number: $PR_NUMBER"
            echo "PR_NUMBER=$PR_NUMBER" >> "$GITHUB_ENV"
          
            HEAD_SHA=$(jq -r '.pull_requests[0].head.sha' \
              <<< "$WORKFLOW_RUN_EVENT_OBJ")
            
            echo "Head SHA: $HEAD_SHA"
            echo "HEAD_SHA=$HEAD_SHA" >> "$GITHUB_ENV"
        - name: Find Comment
          uses: peter-evans/find-comment@v2
          id: find-comment
          with:
            issue-number: ${{ env.PR_NUMBER }}
            comment-author: 'github-actions[bot]'
        - name: Update Comment
          env:
            JOB_PATH: "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ env.PREVIOUS_JOB_ID }}"
            ARTIFACT_URL: "${{ github.server_url }}/${{ github.repository }}/suites/$SUITE_ID/artifacts/$ARTIFACT_ID"
            HEAD_SHA: "${{ env.HEAD_SHA }}"
          uses: peter-evans/create-or-update-comment@v3
          with:
            issue-number: ${{ env.PR_NUMBER }}
            comment-id: ${{ steps.find-comment.outputs.comment-id }}
            edit-mode: replace
            body: |-
              ![badge]
              
              Build Successful! You can find a link to the downloadable artifact below.
              
              | Name     | Link                    |
              | -------- | ----------------------- |
              | Commit   | ${{ env.HEAD_SHA }}     |
              | Logs     | ${{ env.JOB_PATH }}     |
              | Download | ${{ env.ARTIFACT_URL }} |
      # OR imitates an if here as linux checks the first command firsta
        - name: fail-on-tests-failing
          if: ${{ env.RESULT != env.PASS }}
          uses: actions/github-script@v7
          with:
           script: |
                core.setFailed('Tests Failed!')
              
              

